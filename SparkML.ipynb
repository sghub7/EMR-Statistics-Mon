{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlr9f6ioqG2x0Yr6P62N+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sghub7/EMR-Statistics-Mon/blob/master/SparkML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAnuRcyZZ2hu"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRpN2R5Iaxp5"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPzcMuWJa5N4",
        "outputId": "11f63afd-0eff-4b8b-842d-bf3df06cfa55"
      },
      "source": [
        "!tar -xvf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.1.2-bin-hadoop2.7/\n",
            "spark-3.1.2-bin-hadoop2.7/R/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/decommission-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/decommission-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.1.2-bin-hadoop2.7/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/python_executable_check.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/decommissioning.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/autoscale.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/yarn/\n",
            "spark-3.1.2-bin-hadoop2.7/yarn/spark-3.1.2-yarn-shuffle.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zstd-jni-1.4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-yarn_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-unsafe_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-tags_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-tags_2.12-3.1.2-tests.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-streaming_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-sql_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-sketch_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-repl_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-network-common_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mllib_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mesos_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-launcher_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-kvstore_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-hive_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-graphx_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-core_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-catalyst_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/snappy-java-1.1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/shims-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/py4j-0.10.9.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-shims-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-mapreduce-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-core-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/okio-1.14.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/okhttp-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/objenesis-2.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/netty-all-4.1.51.Final.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-storageclass-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-settings-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-scheduling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-rbac-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-policy-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-networking-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-metrics-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-extensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-events-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-discovery-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-core-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-coordination-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-common-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-certificates-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-batch-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-autoscaling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-apps-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-apiextensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-client-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-server-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-hk2-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-common-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-client-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-serde-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-cli-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-lang3-3.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-compress-1.20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/chill-java-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-format-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/antlr4-runtime-4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/python/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.1.2-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/version.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/taskcontext.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/listener.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/storagelevel.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/status.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/statcounter.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/regression.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/random.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/feature.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/common.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/classification.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/util.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tree.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/util.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tree.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/stat.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/regression.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/image.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/feature.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/common.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/classification.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/base.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tuning.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/install.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/files.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/conf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/broadcast.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/accumulators.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/window.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/udf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/types.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/streaming.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/session.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/group.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/conf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/column.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/catalog.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resultiterable.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/requests.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/requests.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/information.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/information.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/profile.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/profile.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rdd.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/py.typed\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/profiler.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/quickstart.ipynb\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/install.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/testing.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/setting_ide.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/debugging.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/contributing.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/css/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/copybutton.js\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.1.2-bin-hadoop2.7/python/README.md\n",
            "spark-3.1.2-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.1.2-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.1.2-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.1.2-bin-hadoop2.7/python/setup.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.1.2-bin-hadoop2.7/python/mypy.ini\n",
            "spark-3.1.2-bin-hadoop2.7/bin/\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.1.2-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/run-example\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.1.2-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.1.2-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.1.2-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/beeline\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.1.2-bin-hadoop2.7/README.md\n",
            "spark-3.1.2-bin-hadoop2.7/conf/\n",
            "spark-3.1.2-bin-hadoop2.7/conf/workers.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.1.2-bin-hadoop2.7/data/\n",
            "spark-3.1.2-bin-hadoop2.7/data/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.1.2-bin-hadoop2.7/NOTICE\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.1.2-bin-hadoop2.7/LICENSE\n",
            "spark-3.1.2-bin-hadoop2.7/RELEASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeV4TKs8a-9B"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh28ohwCbeFw",
        "outputId": "c797ebee-e942-460f-d67a-d48f272dc696"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 66 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 50.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=bbfd726b4c5908949bd7f5cd12d1acbc225dfc7596ade4e9c6bcfd2b02e84870\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSpa7f5GbfeZ"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhgtZpoabt3Y"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evbj4H9uc_iG"
      },
      "source": [
        "Basic Statistics on Spark ML. \n",
        "Spark ML adds few extra data structures as part of ML Lib ->\n",
        "Here we show Dense Vector , Sparse Vector , Matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNDVScWbx6g"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.stat import Correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmXoUOTb3mQ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6fk5rgPb6r_"
      },
      "source": [
        "data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n",
        "        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
        "        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
        "        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n",
        "df = spark.createDataFrame(data, [\"features\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSSY6JC6cFSf",
        "outputId": "a75e5759-602e-4b4c-f21e-2df6845f06d2"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(4,[0,3],[1.0,-2.0])|\n",
            "|   [4.0,5.0,0.0,3.0]|\n",
            "|   [6.0,7.0,0.0,8.0]|\n",
            "| (4,[0,3],[9.0,1.0])|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S9D4RMdclQA",
        "outputId": "629a63e7-53a1-49b7-db25-e82102ceb122"
      },
      "source": [
        "r1 = Correlation.corr(df, \"features\").head()\n",
        "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n",
        "\n",
        "r2 = Correlation.corr(df, \"features\", \"spearman\").head()\n",
        "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation matrix:\n",
            "DenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n",
            "             [0.05564149, 1.        ,        nan, 0.91359586],\n",
            "             [       nan,        nan, 1.        ,        nan],\n",
            "             [0.40047142, 0.91359586,        nan, 1.        ]])\n",
            "Spearman correlation matrix:\n",
            "DenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n",
            "             [0.10540926, 1.        ,        nan, 0.9486833 ],\n",
            "             [       nan,        nan, 1.        ,        nan],\n",
            "             [0.4       , 0.9486833 ,        nan, 1.        ]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VRm7-OrvoCd"
      },
      "source": [
        "Matrix Multiplication Demo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q67qgYUEvuiF"
      },
      "source": [
        "from pyspark.mllib.linalg.distributed import *\n",
        "from pyspark.mllib.linalg import Matrices\n",
        "sc= spark.sparkContext\n",
        "dm1 = Matrices.dense(2, 3, [1, 2, 3, 4, 5, 6])\n",
        "dm2 = Matrices.dense(2, 3, [7, 8, 9, 10, 11, 12])\n",
        "dm3 = Matrices.dense(3, 2, [1, 2, 3, 4, 5, 6])\n",
        "dm4 = Matrices.dense(3, 2, [7, 8, 9, 10, 11, 12])\n",
        "sm = Matrices.sparse(3, 2, [0, 1, 3], [0, 1, 2], [7, 11, 12])\n",
        "blocks1 = sc.parallelize([((0, 0), dm1), ((0, 1), dm2)])\n",
        "blocks2 = sc.parallelize([((0, 0), dm3), ((1, 0), dm4)])\n",
        "\n",
        "mat1 = BlockMatrix(blocks1, 2, 3)\n",
        "mat2 = BlockMatrix(blocks2, 3, 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZPMaYi6zJvU",
        "outputId": "50b86e07-1abd-4b3d-9d00-11c52b51dba2"
      },
      "source": [
        "mat1.multiply(mat2).toLocalMatrix() ## Avoid to LocalMatrix () as it collect the distributed matrix on driver as a dense matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseMatrix(2, 2, [242.0, 272.0, 350.0, 398.0], 0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEtWPjcj8O7K"
      },
      "source": [
        "Machine Learning on Spark ML\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "End to END ML using Spark ML \n",
        "\n",
        "---\n",
        "AirBnb NYC 2019 Data Set and  Predict room prices\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "siafvrPnz9V0",
        "outputId": "e427c920-25cf-4dba-af8f-87957c01395b"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51a27611-6786-4a43-8727-9855fe8e4c09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51a27611-6786-4a43-8727-9855fe8e4c09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AB_NYC_2019.csv to AB_NYC_2019.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBTW8CcArEXc"
      },
      "source": [
        "Step 0 - Load and Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzVd7bRKUO3r",
        "outputId": "9e0bc0ec-fa10-4107-cbf5-ba06d8b179b8"
      },
      "source": [
        "## Doing some Basic EDA\n",
        "airDF = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"multiLine\", \"true\").option(\"inferSchema\",\"true\").load(\"AB_NYC_2019.csv\")\n",
        "airDF.repartition(3) ## Repartioning to distribute. Ideally when you read from HDFS files will be partioned already\n",
        "\n",
        "airDF.cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string, host_id: string, host_name: string, neighbourhood_group: string, neighbourhood: string, latitude: string, longitude: string, room_type: string, price: string, minimum_nights: string, number_of_reviews: double, last_review: string, reviews_per_month: string, calculated_host_listings_count: string, availability_365: int]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2HyuTFpXnZY",
        "outputId": "1b27cf1a-3fd5-4372-8ce0-348453dae101"
      },
      "source": [
        "airDF.show(50,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------------------+-------+----------------+-------------------+-------------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|id   |name                                              |host_id|host_name       |neighbourhood_group|neighbourhood            |latitude|longitude|room_type      |price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
            "+-----+--------------------------------------------------+-------+----------------+-------------------+-------------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|2539 |Clean & quiet apt home by the park                |2787   |John            |Brooklyn           |Kensington               |40.64749|-73.97237|Private room   |149  |1             |9.0              |2018-10-19 |0.21             |6                             |365             |\n",
            "|2595 |Skylit Midtown Castle                             |2845   |Jennifer        |Manhattan          |Midtown                  |40.75362|-73.98377|Entire home/apt|225  |1             |45.0             |2019-05-21 |0.38             |2                             |355             |\n",
            "|3647 |THE VILLAGE OF HARLEM....NEW YORK !               |4632   |Elisabeth       |Manhattan          |Harlem                   |40.80902|-73.9419 |Private room   |150  |3             |0.0              |null       |null             |1                             |365             |\n",
            "|3831 |Cozy Entire Floor of Brownstone                   |4869   |LisaRoxanne     |Brooklyn           |Clinton Hill             |40.68514|-73.95976|Entire home/apt|89   |1             |270.0            |2019-07-05 |4.64             |1                             |194             |\n",
            "|5022 |Entire Apt: Spacious Studio/Loft by central park  |7192   |Laura           |Manhattan          |East Harlem              |40.79851|-73.94399|Entire home/apt|80   |10            |9.0              |2018-11-19 |0.10             |1                             |0               |\n",
            "|5099 |Large Cozy 1 BR Apartment In Midtown East         |7322   |Chris           |Manhattan          |Murray Hill              |40.74767|-73.975  |Entire home/apt|200  |3             |74.0             |2019-06-22 |0.59             |1                             |129             |\n",
            "|5121 |BlissArtsSpace!                                   |7356   |Garon           |Brooklyn           |Bedford-Stuyvesant       |40.68688|-73.95596|Private room   |60   |45            |49.0             |2017-10-05 |0.40             |1                             |0               |\n",
            "|5178 |Large Furnished Room Near B'way                   |8967   |Shunichi        |Manhattan          |Hell's Kitchen           |40.76489|-73.98493|Private room   |79   |2             |430.0            |2019-06-24 |3.47             |1                             |220             |\n",
            "|5203 |Cozy Clean Guest Room - Family Apt                |7490   |MaryEllen       |Manhattan          |Upper West Side          |40.80178|-73.96723|Private room   |79   |2             |118.0            |2017-07-21 |0.99             |1                             |0               |\n",
            "|5238 |Cute & Cozy Lower East Side 1 bdrm                |7549   |Ben             |Manhattan          |Chinatown                |40.71344|-73.99037|Entire home/apt|150  |1             |160.0            |2019-06-09 |1.33             |4                             |188             |\n",
            "|5295 |Beautiful 1br on Upper West Side                  |7702   |Lena            |Manhattan          |Upper West Side          |40.80316|-73.96545|Entire home/apt|135  |5             |53.0             |2019-06-22 |0.43             |1                             |6               |\n",
            "|5441 |Central Manhattan/near Broadway                   |7989   |Kate            |Manhattan          |Hell's Kitchen           |40.76076|-73.98867|Private room   |85   |2             |188.0            |2019-06-23 |1.50             |1                             |39              |\n",
            "|5803 |Lovely Room 1, Garden, Best Area, Legal rental    |9744   |Laurie          |Brooklyn           |South Slope              |40.66829|-73.98779|Private room   |89   |4             |167.0            |2019-06-24 |1.34             |3                             |314             |\n",
            "|6021 |Wonderful Guest Bedroom in Manhattan for SINGLES  |11528  |Claudio         |Manhattan          |Upper West Side          |40.79826|-73.96113|Private room   |85   |2             |113.0            |2019-07-05 |0.91             |1                             |333             |\n",
            "|6090 |West Village Nest - Superhost                     |11975  |Alina           |Manhattan          |West Village             |40.7353 |-74.00525|Entire home/apt|120  |90            |27.0             |2018-10-31 |0.22             |1                             |0               |\n",
            "|6848 |Only 2 stops to Manhattan studio                  |15991  |Allen & Irina   |Brooklyn           |Williamsburg             |40.70837|-73.95352|Entire home/apt|140  |2             |148.0            |2019-06-29 |1.20             |1                             |46              |\n",
            "|7097 |Perfect for Your Parents + Garden                 |17571  |Jane            |Brooklyn           |Fort Greene              |40.69169|-73.97185|Entire home/apt|215  |2             |198.0            |2019-06-28 |1.72             |1                             |321             |\n",
            "|7322 |Chelsea Perfect                                   |18946  |Doti            |Manhattan          |Chelsea                  |40.74192|-73.99501|Private room   |140  |1             |260.0            |2019-07-01 |2.12             |1                             |12              |\n",
            "|7726 |Hip Historic Brownstone Apartment with Backyard   |20950  |Adam And Charity|Brooklyn           |Crown Heights            |40.67592|-73.94694|Entire home/apt|99   |3             |53.0             |2019-06-22 |4.44             |1                             |21              |\n",
            "|7750 |Huge 2 BR Upper East  Cental Park                 |17985  |Sing            |Manhattan          |East Harlem              |40.79685|-73.94872|Entire home/apt|190  |7             |0.0              |null       |null             |2                             |249             |\n",
            "|7801 |Sweet and Spacious Brooklyn Loft                  |21207  |Chaya           |Brooklyn           |Williamsburg             |40.71842|-73.95718|Entire home/apt|299  |3             |9.0              |2011-12-28 |0.07             |1                             |0               |\n",
            "|8024 |CBG CtyBGd HelpsHaiti rm#1:1-4                    |22486  |Lisel           |Brooklyn           |Park Slope               |40.68069|-73.97706|Private room   |130  |2             |130.0            |2019-07-01 |1.09             |6                             |347             |\n",
            "|8025 |CBG Helps Haiti Room#2.5                          |22486  |Lisel           |Brooklyn           |Park Slope               |40.67989|-73.97798|Private room   |80   |1             |39.0             |2019-01-01 |0.37             |6                             |364             |\n",
            "|8110 |CBG Helps Haiti Rm #2                             |22486  |Lisel           |Brooklyn           |Park Slope               |40.68001|-73.97865|Private room   |110  |2             |71.0             |2019-07-02 |0.61             |6                             |304             |\n",
            "|8490 |MAISON DES SIRENES1,bohemian apartment            |25183  |Nathalie        |Brooklyn           |Bedford-Stuyvesant       |40.68371|-73.94028|Entire home/apt|120  |2             |88.0             |2019-06-19 |0.73             |2                             |233             |\n",
            "|8505 |Sunny Bedroom Across Prospect Park                |25326  |Gregory         |Brooklyn           |Windsor Terrace          |40.65599|-73.97519|Private room   |60   |1             |19.0             |2019-06-23 |1.37             |2                             |85              |\n",
            "|8700 |Magnifique Suite au N de Manhattan - vue Cloitres |26394  |Claude & Sophie |Manhattan          |Inwood                   |40.86754|-73.92639|Private room   |80   |4             |0.0              |null       |null             |1                             |0               |\n",
            "|9357 |Midtown Pied-a-terre                              |30193  |Tommi           |Manhattan          |Hell's Kitchen           |40.76715|-73.98533|Entire home/apt|150  |10            |58.0             |2017-08-13 |0.49             |1                             |75              |\n",
            "|9518 |SPACIOUS, LOVELY FURNISHED MANHATTAN BEDROOM      |31374  |Shon            |Manhattan          |Inwood                   |40.86482|-73.92106|Private room   |44   |3             |108.0            |2019-06-15 |1.11             |3                             |311             |\n",
            "|9657 |Modern 1 BR / NYC / EAST VILLAGE                  |21904  |Dana            |Manhattan          |East Village             |40.7292 |-73.98542|Entire home/apt|180  |14            |29.0             |2019-04-19 |0.24             |1                             |67              |\n",
            "|9668 |front room/double bed                             |32294  |Ssameer Or Trip |Manhattan          |Harlem                   |40.82245|-73.95104|Private room   |50   |3             |242.0            |2019-06-01 |2.04             |3                             |355             |\n",
            "|9704 |Spacious 1 bedroom in luxe building               |32045  |Teri            |Manhattan          |Harlem                   |40.81305|-73.95466|Private room   |52   |2             |88.0             |2019-06-14 |1.42             |1                             |255             |\n",
            "|9782 |Loft in Williamsburg Area w/ Roof                 |32169  |Andrea          |Brooklyn           |Greenpoint               |40.72219|-73.93762|Private room   |55   |4             |197.0            |2019-06-15 |1.65             |3                             |284             |\n",
            "|9783 |back room/bunk beds                               |32294  |Ssameer Or Trip |Manhattan          |Harlem                   |40.8213 |-73.95318|Private room   |50   |3             |273.0            |2019-07-01 |2.37             |3                             |359             |\n",
            "|10452|Large B&B Style rooms                             |35935  |Angela          |Brooklyn           |Bedford-Stuyvesant       |40.6831 |-73.95473|Private room   |70   |1             |74.0             |2019-05-12 |0.66             |2                             |269             |\n",
            "|10962|Lovely room 2 & garden; Best area, Legal rental   |9744   |Laurie          |Brooklyn           |South Slope              |40.66869|-73.9878 |Private room   |89   |4             |168.0            |2019-06-21 |1.41             |3                             |340             |\n",
            "|11452|Clean and Quiet in Brooklyn                       |7355   |Vt              |Brooklyn           |Bedford-Stuyvesant       |40.68876|-73.94312|Private room   |35   |60            |0.0              |null       |null             |1                             |365             |\n",
            "|11708|Cute apt in artist's home                         |44145  |Tyrome          |Brooklyn           |Bushwick                 |40.70186|-73.92745|Entire home/apt|85   |2             |231.0            |2019-06-22 |1.96             |2                             |22              |\n",
            "|11943|Country space in the city                         |45445  |Harriet         |Brooklyn           |Flatbush                 |40.63702|-73.96327|Private room   |150  |1             |0.0              |null       |null             |1                             |365             |\n",
            "|12048|LowerEastSide apt share shortterm 1               |7549   |Ben             |Manhattan          |Lower East Side          |40.71401|-73.98917|Shared room    |40   |1             |214.0            |2019-07-05 |1.81             |4                             |188             |\n",
            "|12192|ENJOY Downtown NYC!                               |46978  |Edward          |Manhattan          |East Village             |40.7229 |-73.98199|Private room   |68   |2             |245.0            |2019-06-21 |2.08             |2                             |96              |\n",
            "|12299|Beautiful Sunny Park Slope Brooklyn               |47610  |Abdul           |Brooklyn           |South Slope              |40.66278|-73.97966|Entire home/apt|120  |3             |15.0             |2019-05-27 |0.39             |1                             |345             |\n",
            "|12303|1bdr w private bath. in lofty apt                 |47618  |Yolande         |Brooklyn           |Fort Greene              |40.69673|-73.97584|Private room   |120  |7             |25.0             |2018-09-30 |0.23             |1                             |311             |\n",
            "|12318|West Side Retreat                                 |16800  |Cyn             |Manhattan          |Upper West Side          |40.79009|-73.97927|Private room   |135  |4             |81.0             |2019-06-16 |0.69             |1                             |273             |\n",
            "|12343|BEST BET IN HARLEM                                |47727  |Earl            |Manhattan          |Harlem                   |40.81175|-73.94478|Entire home/apt|150  |7             |97.0             |2019-06-13 |0.84             |1                             |309             |\n",
            "|12627|Entire apartment in central Brooklyn neighborhood.|49670  |Rana            |Brooklyn           |Prospect-Lefferts Gardens|40.65944|-73.96238|Entire home/apt|150  |29            |11.0             |2019-06-05 |0.49             |1                             |95              |\n",
            "|12937|1 Stop fr. Manhattan! Private Suite,Landmark Block|50124  |Orestes         |Queens             |Long Island City         |40.74771|-73.9474 |Private room   |130  |3             |248.0            |2019-07-01 |2.25             |1                             |215             |\n",
            "|12940|Charming Brownstone 3 - Near PRATT                |50148  |Adreinne        |Brooklyn           |Bedford-Stuyvesant       |40.68111|-73.95591|Entire home/apt|110  |7             |61.0             |2019-05-25 |0.52             |1                             |265             |\n",
            "|13050|bright and stylish duplex                         |50846  |Jennifer        |Brooklyn           |Bedford-Stuyvesant       |40.68554|-73.9409 |Entire home/apt|115  |3             |11.0             |2017-01-01 |0.10             |1                             |0               |\n",
            "|13394|Fort Greene brownstone                            |52335  |Alexander       |Brooklyn           |Fort Greene              |40.69142|-73.97376|Private room   |80   |3             |135.0            |2019-06-17 |1.16             |2                             |192             |\n",
            "+-----+--------------------------------------------------+-------+----------------+-------------------+-------------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo_ffmXhfoKX",
        "outputId": "908225f8-da51-48b3-c24c-15d7ea971e55"
      },
      "source": [
        "airDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- host_id: string (nullable = true)\n",
            " |-- host_name: string (nullable = true)\n",
            " |-- neighbourhood_group: string (nullable = true)\n",
            " |-- neighbourhood: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- room_type: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            " |-- minimum_nights: string (nullable = true)\n",
            " |-- number_of_reviews: double (nullable = true)\n",
            " |-- last_review: string (nullable = true)\n",
            " |-- reviews_per_month: string (nullable = true)\n",
            " |-- calculated_host_listings_count: string (nullable = true)\n",
            " |-- availability_365: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILN3bC1BgMRo",
        "outputId": "76743c06-0e9a-400d-c1ab-f31bf5626e58"
      },
      "source": [
        "## Describe the dataframe. \n",
        "## Explore Dataframe\n",
        "##Describe function describe returns a DataFrame containing information such as number of non-null entries (count), mean, standard deviation, and minimum and maximum value for each numerical column\n",
        "airDF.describe().show(1,False) ## Just displaying the count here"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+-------+---------+-------------------+-------------+--------+---------+---------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|summary|id   |name |host_id|host_name|neighbourhood_group|neighbourhood|latitude|longitude|room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
            "+-------+-----+-----+-------+---------+-------------------+-------------+--------+---------+---------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|count  |48895|48879|48895  |48874    |48895              |48895        |48895   |48895    |48895    |48895|48895         |48895            |38843      |38843            |48895                         |48895           |\n",
            "+-------+-----+-----+-------+---------+-------------------+-------------+--------+---------+---------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg50mFs0XrPH",
        "outputId": "601d43e4-277d-4a96-b204-48aa9ff7a0f7"
      },
      "source": [
        "## Neighbourhoods having the highest number of rentals\n",
        "from pyspark.sql.functions import col\n",
        "airDF.groupBy(\"neighbourhood\").count().orderBy(col(\"count\").desc()).show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|     neighbourhood|count|\n",
            "+------------------+-----+\n",
            "|      Williamsburg| 3920|\n",
            "|Bedford-Stuyvesant| 3714|\n",
            "|            Harlem| 2655|\n",
            "|          Bushwick| 2465|\n",
            "|   Upper West Side| 1971|\n",
            "|    Hell's Kitchen| 1958|\n",
            "|      East Village| 1853|\n",
            "|   Upper East Side| 1798|\n",
            "|     Crown Heights| 1563|\n",
            "|           Midtown| 1545|\n",
            "|       East Harlem| 1117|\n",
            "|        Greenpoint| 1115|\n",
            "|           Chelsea| 1113|\n",
            "|   Lower East Side|  911|\n",
            "|           Astoria|  900|\n",
            "|Washington Heights|  899|\n",
            "|      West Village|  767|\n",
            "|Financial District|  744|\n",
            "|          Flatbush|  621|\n",
            "|      Clinton Hill|  572|\n",
            "+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FO_EdV-ZlBm",
        "outputId": "3399029b-2be5-414a-b956-b57eea8c3c52"
      },
      "source": [
        "## Let's run some Statistics on price column\n",
        "airDF.select(\"price\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|             price|\n",
            "+-------+------------------+\n",
            "|  count|             48895|\n",
            "|   mean|152.72225387032114|\n",
            "| stddev|240.16757937623433|\n",
            "|    min|         -74.00828|\n",
            "|    max|      Private room|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5ucrhQvevGc",
        "outputId": "4cadae89-4524-48f7-f2e5-063f907c5688"
      },
      "source": [
        "## Price of -73** and \"private room\" ??.. Let's explore\n",
        "airDF.filter(\"price == 'Private room' or price == '-73.99986' \").show(10,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------+--------------+---------+-------------------+-------------+--------+---------+---------+------------+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|id      |name                                  |host_id       |host_name|neighbourhood_group|neighbourhood|latitude|longitude|room_type|price       |minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
            "+--------+--------------------------------------+--------------+---------+-------------------+-------------+--------+---------+---------+------------+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "|4681219 |\"\"\"Central Park\"\" View Prvt Room      |Mnh  \"        |24208781 |William Hakan      |Manhattan    |Harlem  |40.80126 |-73.95777|Private room|70            |2.0              |68         |2019-05-19       |1.31                          |1               |\n",
            "|33075317|\"\"\"Bushwick in Manhattan\"\" Interactive| Private Room\"|247446830|Krista             |Manhattan    |Harlem  |40.82576 |-73.94861|Private room|73            |2.0              |14         |2019-07-02       |3.72                          |2               |\n",
            "+--------+--------------------------------------+--------------+---------+-------------------+-------------+--------+---------+---------+------------+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czCU_mlFktNx"
      },
      "source": [
        "## Let's drop these rows for now\n",
        "airDF=airDF.filter(\"price != 'Private room' and  price != '-73.99986' \")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgqs5GxDnCex",
        "outputId": "a8398cfc-87e7-4620-a289-e6aedb7b2ebf"
      },
      "source": [
        "airDF.select(\"price\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|             price|\n",
            "+-------+------------------+\n",
            "|  count|             48893|\n",
            "|   mean|152.72225387032114|\n",
            "| stddev|240.16757937623433|\n",
            "|    min|         -74.00828|\n",
            "|    max|         Manhattan|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySad3RVDnx_4"
      },
      "source": [
        "airDF=airDF.filter(\"price not like '%-%' and price not like '%a%' \") ## A Crude way of data cleanin. There may be better ways"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBkNIJbyojm_",
        "outputId": "80c9336d-1da5-4086-b11c-ffa9d8327d68"
      },
      "source": [
        "airDF.select(\"price\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|             price|\n",
            "+-------+------------------+\n",
            "|  count|             48889|\n",
            "|   mean|152.72689152979197|\n",
            "| stddev|240.16784649612146|\n",
            "|    min|                 0|\n",
            "|    max|              9999|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fT6WQuQtrS8"
      },
      "source": [
        "#Let's convert  columns to Double type to perform some more analysis\n",
        "from pyspark.sql.functions import expr\n",
        "airDF = airDF.withColumn(\"priceDouble\",expr(\"CAST (price as Double)\")).drop(\"price\").withColumnRenamed(\"priceDouble\",\"price\")\n",
        "airDF = airDF.withColumn(\"minimum_nights_d\",expr(\"CAST (minimum_nights as Double)\")).drop(\"minimum_nights\").withColumnRenamed(\"minimum_nights_d\",\"minimum_nights\")\n",
        "airDF = airDF.withColumn(\"latitude_d\",expr(\"CAST (latitude as Double)\")).drop(\"latitude\").withColumnRenamed(\"latitude_d\",\"latitude\")\n",
        "airDF = airDF.withColumn(\"longitude_d\",expr(\"CAST (longitude as Double)\")).drop(\"longitude\").withColumnRenamed(\"longitude_d\",\"longitude\")\n",
        "airDF = airDF.withColumn(\"reviews_per_month_double\",expr(\"CAST (reviews_per_month as Double)\")).drop(\"reviews_per_month\").withColumnRenamed(\"reviews_per_month_double\",\"reviews_per_month\")\n",
        "airDF = airDF.withColumn(\"calculated_host_listings_count_d\",expr(\"CAST (calculated_host_listings_count as Double)\")).drop(\"calculated_host_listings_count\").withColumnRenamed(\"calculated_host_listings_count_d\",\"calculated_host_listings_count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5kUEAtaCgca",
        "outputId": "b716b7e3-3f42-469b-935c-746e786fa28c"
      },
      "source": [
        "airDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- host_id: string (nullable = true)\n",
            " |-- host_name: string (nullable = true)\n",
            " |-- neighbourhood_group: string (nullable = true)\n",
            " |-- neighbourhood: string (nullable = true)\n",
            " |-- room_type: string (nullable = true)\n",
            " |-- number_of_reviews: double (nullable = true)\n",
            " |-- last_review: string (nullable = true)\n",
            " |-- availability_365: integer (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- minimum_nights: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- reviews_per_month: double (nullable = true)\n",
            " |-- calculated_host_listings_count: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruR1zQPmDrRr",
        "outputId": "e5693b21-ec5e-4d53-ead6-c48adbfc8d9f"
      },
      "source": [
        "## See some stats on the numeric columns\n",
        "airDF.select(\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\"latitude\",\"longitude\",\"calculated_host_listings_count\",\"price\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+\n",
            "|summary|   minimum_nights| number_of_reviews| reviews_per_month|           latitude|         longitude|calculated_host_listings_count|             price|\n",
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+\n",
            "|  count|            48889|             48889|             38837|              48889|             48889|                         48889|             48889|\n",
            "|   mean|7.030436294462967|23.274438012640882|1.3731660529907315|  40.72894774120974|-73.95216762625476|             7.144633762195995|152.72689152979197|\n",
            "| stddev|20.51173512492114| 44.55236615217496|1.6805070568202156|0.05452421651616377|0.0461582750776722|             32.95448440433164|240.16784649612146|\n",
            "|    min|              1.0|               0.0|              0.01|           40.49979|         -74.24442|                           1.0|               0.0|\n",
            "|    max|           1250.0|             629.0|              58.5|           40.91306|         -73.71299|                         327.0|           10000.0|\n",
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBdoEqOiYJdY"
      },
      "source": [
        "from pyspark.sql.functions import log\n",
        "airDF = airDF.withColumn(\"log_price\",log(\"price\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijh0YG7-YgDx",
        "outputId": "33f6a1d5-ad84-4670-dbc6-85b6bc0cdaab"
      },
      "source": [
        "airDF.select(\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\"latitude\",\"longitude\",\"calculated_host_listings_count\",\"price\",\"log_price\").describe().show()\n",
        "## This shows we have some nulls in price. Lets remove them"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+------------------+\n",
            "|summary|   minimum_nights| number_of_reviews| reviews_per_month|           latitude|         longitude|calculated_host_listings_count|             price|         log_price|\n",
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+------------------+\n",
            "|  count|            48889|             48889|             38837|              48889|             48889|                         48889|             48889|             48878|\n",
            "|   mean|7.030436294462967|23.274438012640882|1.3731660529907315|  40.72894774120974|-73.95216762625476|             7.144633762195995|152.72689152979197| 4.727052069177271|\n",
            "| stddev|20.51173512492114| 44.55236615217496|1.6805070568202156|0.05452421651616377|0.0461582750776722|             32.95448440433164|240.16784649612146|0.6982527381416339|\n",
            "|    min|              1.0|               0.0|              0.01|           40.49979|         -74.24442|                           1.0|               0.0| 2.302585092994046|\n",
            "|    max|           1250.0|             629.0|              58.5|           40.91306|         -73.71299|                         327.0|           10000.0| 9.210340371976184|\n",
            "+-------+-----------------+------------------+------------------+-------------------+------------------+------------------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL3pDBODZZYQ"
      },
      "source": [
        "## This shows we have some nulls in price. Lets remove them\n",
        "airDF=airDF.filter(airDF.log_price. isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12YkTpprZyxB",
        "outputId": "449fab2d-f6de-473a-e53c-0cdaedde1a10"
      },
      "source": [
        "airDF.select(\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\"latitude\",\"longitude\",\"calculated_host_listings_count\",\"price\",\"log_price\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+-------------------+-------------------+------------------------------+------------------+------------------+\n",
            "|summary|    minimum_nights| number_of_reviews| reviews_per_month|           latitude|          longitude|calculated_host_listings_count|             price|         log_price|\n",
            "+-------+------------------+------------------+------------------+-------------------+-------------------+------------------------------+------------------+------------------+\n",
            "|  count|             48878|             48878|             38827|              48878|              48878|                         48878|             48878|             48878|\n",
            "|   mean|7.0303613077458165|23.271962846270306| 1.373072346562986| 40.728951542207184| -73.95217358954885|            7.1452800851098655|152.76126273579115| 4.727052069177271|\n",
            "| stddev|20.513409920704554|44.553114906053395|1.6804557707293224|0.05452591012206169|0.04616027941329833|            32.958151217812706|240.18394010612948|0.6982527381416339|\n",
            "|    min|               1.0|               0.0|              0.01|           40.49979|          -74.24442|                           1.0|              10.0| 2.302585092994046|\n",
            "|    max|            1250.0|             629.0|              58.5|           40.91306|          -73.71299|                         327.0|           10000.0| 9.210340371976184|\n",
            "+-------+------------------+------------------+------------------+-------------------+-------------------+------------------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UhVIprKE71b",
        "outputId": "f73bd684-b96d-4285-e9be-7b45ef4decea"
      },
      "source": [
        "## Lets impute reviews_per_month Cloumn\n",
        "##  Imputation strategies -> Mean ( default) , Median , Mode ( Most common value in the column)\n",
        "\n",
        "##Lets covert column to Numeric before imputing\n",
        "airDF = airDF.withColumn(\"reviews_per_month_double\",expr(\"CAST (reviews_per_month as Double)\")).drop(\"reviews_per_month\").withColumnRenamed(\"reviews_per_month_double\",\"reviews_per_month\")\n",
        "\n",
        "airDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- host_id: string (nullable = true)\n",
            " |-- host_name: string (nullable = true)\n",
            " |-- neighbourhood_group: string (nullable = true)\n",
            " |-- neighbourhood: string (nullable = true)\n",
            " |-- room_type: string (nullable = true)\n",
            " |-- number_of_reviews: double (nullable = true)\n",
            " |-- last_review: string (nullable = true)\n",
            " |-- availability_365: integer (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- minimum_nights: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- calculated_host_listings_count: double (nullable = true)\n",
            " |-- log_price: double (nullable = true)\n",
            " |-- reviews_per_month: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGBCdOIojpEq",
        "outputId": "74b7da66-ea02-4356-d781-f83500c87ae4"
      },
      "source": [
        "# Define the imputer\n",
        "from pyspark.ml.feature import Imputer\n",
        "imputer = Imputer(inputCols=[\"reviews_per_month\"], outputCols=[\"reviews_per_month_imputed\"])\n",
        "model = imputer.fit(airDF)\n",
        "airDF= model.transform(airDF)\n",
        "airDF.show(10,False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+-----------------+-------------------------+\n",
            "|id  |name                                            |host_id|host_name  |neighbourhood_group|neighbourhood     |room_type      |number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|log_price         |reviews_per_month|reviews_per_month_imputed|\n",
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+-----------------+-------------------------+\n",
            "|2539|Clean & quiet apt home by the park              |2787   |John       |Brooklyn           |Kensington        |Private room   |9.0              |2018-10-19 |365             |149.0|1.0           |40.64749|-73.97237|6.0                           |5.003946305945459 |0.21             |0.21                     |\n",
            "|2595|Skylit Midtown Castle                           |2845   |Jennifer   |Manhattan          |Midtown           |Entire home/apt|45.0             |2019-05-21 |355             |225.0|1.0           |40.75362|-73.98377|2.0                           |5.41610040220442  |0.38             |0.38                     |\n",
            "|3647|THE VILLAGE OF HARLEM....NEW YORK !             |4632   |Elisabeth  |Manhattan          |Harlem            |Private room   |0.0              |null       |365             |150.0|3.0           |40.80902|-73.9419 |1.0                           |5.0106352940962555|null             |1.373072346562986        |\n",
            "|3831|Cozy Entire Floor of Brownstone                 |4869   |LisaRoxanne|Brooklyn           |Clinton Hill      |Entire home/apt|270.0            |2019-07-05 |194             |89.0 |1.0           |40.68514|-73.95976|1.0                           |4.48863636973214  |4.64             |4.64                     |\n",
            "|5022|Entire Apt: Spacious Studio/Loft by central park|7192   |Laura      |Manhattan          |East Harlem       |Entire home/apt|9.0              |2018-11-19 |0               |80.0 |10.0          |40.79851|-73.94399|1.0                           |4.382026634673881 |0.1              |0.1                      |\n",
            "|5099|Large Cozy 1 BR Apartment In Midtown East       |7322   |Chris      |Manhattan          |Murray Hill       |Entire home/apt|74.0             |2019-06-22 |129             |200.0|3.0           |40.74767|-73.975  |1.0                           |5.298317366548036 |0.59             |0.59                     |\n",
            "|5121|BlissArtsSpace!                                 |7356   |Garon      |Brooklyn           |Bedford-Stuyvesant|Private room   |49.0             |2017-10-05 |0               |60.0 |45.0          |40.68688|-73.95596|1.0                           |4.0943445622221   |0.4              |0.4                      |\n",
            "|5178|Large Furnished Room Near B'way                 |8967   |Shunichi   |Manhattan          |Hell's Kitchen    |Private room   |430.0            |2019-06-24 |220             |79.0 |2.0           |40.76489|-73.98493|1.0                           |4.3694478524670215|3.47             |3.47                     |\n",
            "|5203|Cozy Clean Guest Room - Family Apt              |7490   |MaryEllen  |Manhattan          |Upper West Side   |Private room   |118.0            |2017-07-21 |0               |79.0 |2.0           |40.80178|-73.96723|1.0                           |4.3694478524670215|0.99             |0.99                     |\n",
            "|5238|Cute & Cozy Lower East Side 1 bdrm              |7549   |Ben        |Manhattan          |Chinatown         |Entire home/apt|160.0            |2019-06-09 |188             |150.0|1.0           |40.71344|-73.99037|4.0                           |5.0106352940962555|1.33             |1.33                     |\n",
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+-----------------+-------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPK1ML3mktqY"
      },
      "source": [
        "## Drop reviews_per_month column and use the new imputed reviews_per_month column\n",
        "airDF = airDF.drop (\"reviews_per_month\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ylBFV5oFUq9"
      },
      "source": [
        "airDF=airDF.withColumnRenamed(\"reviews_per_month_imputed\",\"reviews_per_month\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnGSEqenEcRc",
        "outputId": "63bad346-5da0-4a66-ff01-a71dadb0901d"
      },
      "source": [
        "airDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- host_id: string (nullable = true)\n",
            " |-- host_name: string (nullable = true)\n",
            " |-- neighbourhood_group: string (nullable = true)\n",
            " |-- neighbourhood: string (nullable = true)\n",
            " |-- room_type: string (nullable = true)\n",
            " |-- number_of_reviews: double (nullable = true)\n",
            " |-- last_review: string (nullable = true)\n",
            " |-- availability_365: integer (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- minimum_nights: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- calculated_host_listings_count: double (nullable = true)\n",
            " |-- log_price: double (nullable = true)\n",
            " |-- reviews_per_month: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OzU-zU9q8j3"
      },
      "source": [
        "Step 1 - Featurization\n",
        "Doc - https://spark.apache.org/docs/latest/ml-features.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBBMwG0yZy0"
      },
      "source": [
        "# Encode Categorical Variables\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "neighbourhood_i = StringIndexer(inputCol=\"neighbourhood\", outputCol=\"neighbourhood_indexed\", handleInvalid=\"skip\")\n",
        "neighbourhood_group_i = StringIndexer(inputCol=\"neighbourhood_group\", outputCol=\"neighbourhood_group_indexed\", handleInvalid=\"skip\")\n",
        "roomtype_i = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_indexed\", handleInvalid=\"skip\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPb9lgZS4ofh",
        "outputId": "ca43dd86-1bd5-47b1-82ae-c0870999d611"
      },
      "source": [
        "## See how the indexed column looks like\n",
        "## This is just for checking and showcase purpose. We will asseble all stages finally in a pipeline object\n",
        "index_neighbourhood_model = neighbourhood_i.fit(airDF)\n",
        "airDF_dummy= index_neighbourhood_model.transform(airDF)\n",
        "airDF_dummy.show(10,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+\n",
            "|id  |name                                            |host_id|host_name  |neighbourhood_group|neighbourhood     |room_type      |number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|log_price         |reviews_per_month |neighbourhood_indexed|\n",
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+\n",
            "|2539|Clean & quiet apt home by the park              |2787   |John       |Brooklyn           |Kensington        |Private room   |9.0              |2018-10-19 |365             |149.0|1.0           |40.64749|-73.97237|6.0                           |5.003946305945459 |0.21              |52.0                 |\n",
            "|2595|Skylit Midtown Castle                           |2845   |Jennifer   |Manhattan          |Midtown           |Entire home/apt|45.0             |2019-05-21 |355             |225.0|1.0           |40.75362|-73.98377|2.0                           |5.41610040220442  |0.38              |9.0                  |\n",
            "|3647|THE VILLAGE OF HARLEM....NEW YORK !             |4632   |Elisabeth  |Manhattan          |Harlem            |Private room   |0.0              |null       |365             |150.0|3.0           |40.80902|-73.9419 |1.0                           |5.0106352940962555|1.3731660529907315|2.0                  |\n",
            "|3831|Cozy Entire Floor of Brownstone                 |4869   |LisaRoxanne|Brooklyn           |Clinton Hill      |Entire home/apt|270.0            |2019-07-05 |194             |89.0 |1.0           |40.68514|-73.95976|1.0                           |4.48863636973214  |4.64              |19.0                 |\n",
            "|5022|Entire Apt: Spacious Studio/Loft by central park|7192   |Laura      |Manhattan          |East Harlem       |Entire home/apt|9.0              |2018-11-19 |0               |80.0 |10.0          |40.79851|-73.94399|1.0                           |4.382026634673881 |0.1               |10.0                 |\n",
            "|5099|Large Cozy 1 BR Apartment In Midtown East       |7322   |Chris      |Manhattan          |Murray Hill       |Entire home/apt|74.0             |2019-06-22 |129             |200.0|3.0           |40.74767|-73.975  |1.0                           |5.298317366548036 |0.59              |25.0                 |\n",
            "|5121|BlissArtsSpace!                                 |7356   |Garon      |Brooklyn           |Bedford-Stuyvesant|Private room   |49.0             |2017-10-05 |0               |60.0 |45.0          |40.68688|-73.95596|1.0                           |4.0943445622221   |0.4               |1.0                  |\n",
            "|5178|Large Furnished Room Near B'way                 |8967   |Shunichi   |Manhattan          |Hell's Kitchen    |Private room   |430.0            |2019-06-24 |220             |79.0 |2.0           |40.76489|-73.98493|1.0                           |4.3694478524670215|3.47              |5.0                  |\n",
            "|5203|Cozy Clean Guest Room - Family Apt              |7490   |MaryEllen  |Manhattan          |Upper West Side   |Private room   |118.0            |2017-07-21 |0               |79.0 |2.0           |40.80178|-73.96723|1.0                           |4.3694478524670215|0.99              |4.0                  |\n",
            "|5238|Cute & Cozy Lower East Side 1 bdrm              |7549   |Ben        |Manhattan          |Chinatown         |Entire home/apt|160.0            |2019-06-09 |188             |150.0|1.0           |40.71344|-73.99037|4.0                           |5.0106352940962555|1.33              |31.0                 |\n",
            "+----+------------------------------------------------+-------+-----------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GWUFCjD3bXa",
        "outputId": "771d7f2b-2957-4dda-e4cf-3c5548537f47"
      },
      "source": [
        "# Vectorize Encoded Columns\n",
        "## This is just for checking and showcase purpose. We will asseble all stages finally in a pipeline object\n",
        "\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "oneHotEnc_Neighbourhood= OneHotEncoder(\n",
        "  inputCols=[\"neighbourhood_indexed\"],\n",
        "  outputCols=[\"oneHot_neighborhood\"]\n",
        ")\n",
        "oneHotEnc_Neighbourhood_model = oneHotEnc_Neighbourhood.fit(airDF_dummy)\n",
        "airDF_dummy_onehot = oneHotEnc_Neighbourhood_model.transform(airDF_dummy)\n",
        "airDF_dummy_onehot.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+-------------------+\n",
            "|  id|                name|host_id|       host_name|neighbourhood_group|     neighbourhood|      room_type|number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|         log_price| reviews_per_month|neighbourhood_indexed|oneHot_neighborhood|\n",
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+-------------------+\n",
            "|2539|Clean & quiet apt...|   2787|            John|           Brooklyn|        Kensington|   Private room|              9.0| 2018-10-19|             365|149.0|           1.0|40.64749|-73.97237|                           6.0| 5.003946305945459|              0.21|                 52.0|   (220,[52],[1.0])|\n",
            "|2595|Skylit Midtown Ca...|   2845|        Jennifer|          Manhattan|           Midtown|Entire home/apt|             45.0| 2019-05-21|             355|225.0|           1.0|40.75362|-73.98377|                           2.0|  5.41610040220442|              0.38|                  9.0|    (220,[9],[1.0])|\n",
            "|3647|THE VILLAGE OF HA...|   4632|       Elisabeth|          Manhattan|            Harlem|   Private room|              0.0|       null|             365|150.0|           3.0|40.80902| -73.9419|                           1.0|5.0106352940962555|1.3731660529907315|                  2.0|    (220,[2],[1.0])|\n",
            "|3831|Cozy Entire Floor...|   4869|     LisaRoxanne|           Brooklyn|      Clinton Hill|Entire home/apt|            270.0| 2019-07-05|             194| 89.0|           1.0|40.68514|-73.95976|                           1.0|  4.48863636973214|              4.64|                 19.0|   (220,[19],[1.0])|\n",
            "|5022|Entire Apt: Spaci...|   7192|           Laura|          Manhattan|       East Harlem|Entire home/apt|              9.0| 2018-11-19|               0| 80.0|          10.0|40.79851|-73.94399|                           1.0| 4.382026634673881|               0.1|                 10.0|   (220,[10],[1.0])|\n",
            "|5099|Large Cozy 1 BR A...|   7322|           Chris|          Manhattan|       Murray Hill|Entire home/apt|             74.0| 2019-06-22|             129|200.0|           3.0|40.74767|  -73.975|                           1.0| 5.298317366548036|              0.59|                 25.0|   (220,[25],[1.0])|\n",
            "|5121|     BlissArtsSpace!|   7356|           Garon|           Brooklyn|Bedford-Stuyvesant|   Private room|             49.0| 2017-10-05|               0| 60.0|          45.0|40.68688|-73.95596|                           1.0|   4.0943445622221|               0.4|                  1.0|    (220,[1],[1.0])|\n",
            "|5178|Large Furnished R...|   8967|        Shunichi|          Manhattan|    Hell's Kitchen|   Private room|            430.0| 2019-06-24|             220| 79.0|           2.0|40.76489|-73.98493|                           1.0|4.3694478524670215|              3.47|                  5.0|    (220,[5],[1.0])|\n",
            "|5203|Cozy Clean Guest ...|   7490|       MaryEllen|          Manhattan|   Upper West Side|   Private room|            118.0| 2017-07-21|               0| 79.0|           2.0|40.80178|-73.96723|                           1.0|4.3694478524670215|              0.99|                  4.0|    (220,[4],[1.0])|\n",
            "|5238|Cute & Cozy Lower...|   7549|             Ben|          Manhattan|         Chinatown|Entire home/apt|            160.0| 2019-06-09|             188|150.0|           1.0|40.71344|-73.99037|                           4.0|5.0106352940962555|              1.33|                 31.0|   (220,[31],[1.0])|\n",
            "|5295|Beautiful 1br on ...|   7702|            Lena|          Manhattan|   Upper West Side|Entire home/apt|             53.0| 2019-06-22|               6|135.0|           5.0|40.80316|-73.96545|                           1.0|  4.90527477843843|              0.43|                  4.0|    (220,[4],[1.0])|\n",
            "|5441|Central Manhattan...|   7989|            Kate|          Manhattan|    Hell's Kitchen|   Private room|            188.0| 2019-06-23|              39| 85.0|           2.0|40.76076|-73.98867|                           1.0| 4.442651256490317|               1.5|                  5.0|    (220,[5],[1.0])|\n",
            "|5803|Lovely Room 1, Ga...|   9744|          Laurie|           Brooklyn|       South Slope|   Private room|            167.0| 2019-06-24|             314| 89.0|           4.0|40.66829|-73.98779|                           3.0|  4.48863636973214|              1.34|                 39.0|   (220,[39],[1.0])|\n",
            "|6021|Wonderful Guest B...|  11528|         Claudio|          Manhattan|   Upper West Side|   Private room|            113.0| 2019-07-05|             333| 85.0|           2.0|40.79826|-73.96113|                           1.0| 4.442651256490317|              0.91|                  4.0|    (220,[4],[1.0])|\n",
            "|6090|West Village Nest...|  11975|           Alina|          Manhattan|      West Village|Entire home/apt|             27.0| 2018-10-31|               0|120.0|          90.0| 40.7353|-74.00525|                           1.0| 4.787491742782046|              0.22|                 16.0|   (220,[16],[1.0])|\n",
            "|6848|Only 2 stops to M...|  15991|   Allen & Irina|           Brooklyn|      Williamsburg|Entire home/apt|            148.0| 2019-06-29|              46|140.0|           2.0|40.70837|-73.95352|                           1.0| 4.941642422609304|               1.2|                  0.0|    (220,[0],[1.0])|\n",
            "|7097|Perfect for Your ...|  17571|            Jane|           Brooklyn|       Fort Greene|Entire home/apt|            198.0| 2019-06-28|             321|215.0|           2.0|40.69169|-73.97185|                           1.0|5.3706380281276624|              1.72|                 24.0|   (220,[24],[1.0])|\n",
            "|7322|     Chelsea Perfect|  18946|            Doti|          Manhattan|           Chelsea|   Private room|            260.0| 2019-07-01|              12|140.0|           1.0|40.74192|-73.99501|                           1.0| 4.941642422609304|              2.12|                 12.0|   (220,[12],[1.0])|\n",
            "|7726|Hip Historic Brow...|  20950|Adam And Charity|           Brooklyn|     Crown Heights|Entire home/apt|             53.0| 2019-06-22|              21| 99.0|           3.0|40.67592|-73.94694|                           1.0|  4.59511985013459|              4.44|                  8.0|    (220,[8],[1.0])|\n",
            "|7750|Huge 2 BR Upper E...|  17985|            Sing|          Manhattan|       East Harlem|Entire home/apt|              0.0|       null|             249|190.0|           7.0|40.79685|-73.94872|                           2.0| 5.247024072160486|1.3731660529907315|                 10.0|   (220,[10],[1.0])|\n",
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKu65J9C9YeH"
      },
      "source": [
        "# Vectorize All Encoded Columns\n",
        "oneHotEnc = OneHotEncoder(\n",
        "  inputCols=[\"neighbourhood_indexed\", \"neighbourhood_group_indexed\", \"room_type_indexed\"],\n",
        "  outputCols=[\"oneHot_neighborhood\", \"oneHOt_neighbourhood_group\", \"oneHot_room_type\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60N6X7BMBEv9"
      },
      "source": [
        "## What are our feature columns\n",
        "featuresColumns = [\n",
        " \"reviews_per_month\",\n",
        " \"number_of_reviews\",\n",
        " \"availability_365\",\n",
        " \"minimum_nights\",\n",
        " \"latitude\",\n",
        " \"longitude\",\n",
        " \"oneHot_neighborhood\",\n",
        " \"oneHOt_neighbourhood_group\",\n",
        " \"oneHot_room_type\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyIQBcrDdB8"
      },
      "source": [
        "## Assemble our features in a Vector to pass to the ML \n",
        "## Vector assembler is a transformer that combines a given list of columns into a single vector column\n",
        "## Spark ML expects the features in a single vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorized_features = VectorAssembler(inputCols=featuresColumns, outputCol=\"Model_Features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbPseR8MoJAQ"
      },
      "source": [
        "Step 3 - Create the ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUZfkzzcl2o-",
        "outputId": "03a8bc47-bb6e-4a2d-f748-e4ce3f40c617"
      },
      "source": [
        "## We now put all our stages/steps peerformed earlier in a Spark ML Pipeline\n",
        "## Spark will execute the pipeline in sequence\n",
        "\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "features_pipe = Pipeline()\n",
        "features_pipe.setStages([neighbourhood_i, neighbourhood_group_i, roomtype_i,oneHotEnc , vectorized_features])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline_ba7085a6a904"
            ]
          },
          "metadata": {},
          "execution_count": 507
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzo1X2MbH3Gb",
        "outputId": "446346db-0345-466f-f478-e4480355f0aa"
      },
      "source": [
        "## Let's see how the final data set looks\n",
        "features_pipe.fit(airDF).transform(airDF).show()\n",
        "## Model_Features will be the only input column for our model trainig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+\n",
            "|  id|                name|host_id|       host_name|neighbourhood_group|     neighbourhood|      room_type|number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|         log_price| reviews_per_month|neighbourhood_indexed|neighbourhood_group_indexed|room_type_indexed|oneHot_neighborhood|oneHOt_neighbourhood_group|oneHot_room_type|      Model_Features|\n",
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+\n",
            "|2539|Clean & quiet apt...|   2787|            John|           Brooklyn|        Kensington|   Private room|              9.0| 2018-10-19|             365|149.0|           1.0|40.64749|-73.97237|                           6.0| 5.003946305945459|              0.21|                 52.0|                        1.0|              1.0|   (220,[52],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|2595|Skylit Midtown Ca...|   2845|        Jennifer|          Manhattan|           Midtown|Entire home/apt|             45.0| 2019-05-21|             355|225.0|           1.0|40.75362|-73.98377|                           2.0|  5.41610040220442|              0.38|                  9.0|                        0.0|              0.0|    (220,[9],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|3647|THE VILLAGE OF HA...|   4632|       Elisabeth|          Manhattan|            Harlem|   Private room|              0.0|       null|             365|150.0|           3.0|40.80902| -73.9419|                           1.0|5.0106352940962555|1.3731660529907315|                  2.0|                        0.0|              1.0|    (220,[2],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,2,3,4,5,8...|\n",
            "|3831|Cozy Entire Floor...|   4869|     LisaRoxanne|           Brooklyn|      Clinton Hill|Entire home/apt|            270.0| 2019-07-05|             194| 89.0|           1.0|40.68514|-73.95976|                           1.0|  4.48863636973214|              4.64|                 19.0|                        1.0|              0.0|   (220,[19],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5022|Entire Apt: Spaci...|   7192|           Laura|          Manhattan|       East Harlem|Entire home/apt|              9.0| 2018-11-19|               0| 80.0|          10.0|40.79851|-73.94399|                           1.0| 4.382026634673881|               0.1|                 10.0|                        0.0|              0.0|   (220,[10],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,3,4,5,1...|\n",
            "|5099|Large Cozy 1 BR A...|   7322|           Chris|          Manhattan|       Murray Hill|Entire home/apt|             74.0| 2019-06-22|             129|200.0|           3.0|40.74767|  -73.975|                           1.0| 5.298317366548036|              0.59|                 25.0|                        0.0|              0.0|   (220,[25],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5121|     BlissArtsSpace!|   7356|           Garon|           Brooklyn|Bedford-Stuyvesant|   Private room|             49.0| 2017-10-05|               0| 60.0|          45.0|40.68688|-73.95596|                           1.0|   4.0943445622221|               0.4|                  1.0|                        1.0|              1.0|    (220,[1],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(232,[0,1,3,4,5,7...|\n",
            "|5178|Large Furnished R...|   8967|        Shunichi|          Manhattan|    Hell's Kitchen|   Private room|            430.0| 2019-06-24|             220| 79.0|           2.0|40.76489|-73.98493|                           1.0|4.3694478524670215|              3.47|                  5.0|                        0.0|              1.0|    (220,[5],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5203|Cozy Clean Guest ...|   7490|       MaryEllen|          Manhattan|   Upper West Side|   Private room|            118.0| 2017-07-21|               0| 79.0|           2.0|40.80178|-73.96723|                           1.0|4.3694478524670215|              0.99|                  4.0|                        0.0|              1.0|    (220,[4],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,1,3,4,5,1...|\n",
            "|5238|Cute & Cozy Lower...|   7549|             Ben|          Manhattan|         Chinatown|Entire home/apt|            160.0| 2019-06-09|             188|150.0|           1.0|40.71344|-73.99037|                           4.0|5.0106352940962555|              1.33|                 31.0|                        0.0|              0.0|   (220,[31],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5295|Beautiful 1br on ...|   7702|            Lena|          Manhattan|   Upper West Side|Entire home/apt|             53.0| 2019-06-22|               6|135.0|           5.0|40.80316|-73.96545|                           1.0|  4.90527477843843|              0.43|                  4.0|                        0.0|              0.0|    (220,[4],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5441|Central Manhattan...|   7989|            Kate|          Manhattan|    Hell's Kitchen|   Private room|            188.0| 2019-06-23|              39| 85.0|           2.0|40.76076|-73.98867|                           1.0| 4.442651256490317|               1.5|                  5.0|                        0.0|              1.0|    (220,[5],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|5803|Lovely Room 1, Ga...|   9744|          Laurie|           Brooklyn|       South Slope|   Private room|            167.0| 2019-06-24|             314| 89.0|           4.0|40.66829|-73.98779|                           3.0|  4.48863636973214|              1.34|                 39.0|                        1.0|              1.0|   (220,[39],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|6021|Wonderful Guest B...|  11528|         Claudio|          Manhattan|   Upper West Side|   Private room|            113.0| 2019-07-05|             333| 85.0|           2.0|40.79826|-73.96113|                           1.0| 4.442651256490317|              0.91|                  4.0|                        0.0|              1.0|    (220,[4],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|6090|West Village Nest...|  11975|           Alina|          Manhattan|      West Village|Entire home/apt|             27.0| 2018-10-31|               0|120.0|          90.0| 40.7353|-74.00525|                           1.0| 4.787491742782046|              0.22|                 16.0|                        0.0|              0.0|   (220,[16],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,1,3,4,5,2...|\n",
            "|6848|Only 2 stops to M...|  15991|   Allen & Irina|           Brooklyn|      Williamsburg|Entire home/apt|            148.0| 2019-06-29|              46|140.0|           2.0|40.70837|-73.95352|                           1.0| 4.941642422609304|               1.2|                  0.0|                        1.0|              0.0|    (220,[0],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|7097|Perfect for Your ...|  17571|            Jane|           Brooklyn|       Fort Greene|Entire home/apt|            198.0| 2019-06-28|             321|215.0|           2.0|40.69169|-73.97185|                           1.0|5.3706380281276624|              1.72|                 24.0|                        1.0|              0.0|   (220,[24],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|7322|     Chelsea Perfect|  18946|            Doti|          Manhattan|           Chelsea|   Private room|            260.0| 2019-07-01|              12|140.0|           1.0|40.74192|-73.99501|                           1.0| 4.941642422609304|              2.12|                 12.0|                        0.0|              1.0|   (220,[12],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|7726|Hip Historic Brow...|  20950|Adam And Charity|           Brooklyn|     Crown Heights|Entire home/apt|             53.0| 2019-06-22|              21| 99.0|           3.0|40.67592|-73.94694|                           1.0|  4.59511985013459|              4.44|                  8.0|                        1.0|              0.0|    (220,[8],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(232,[0,1,2,3,4,5...|\n",
            "|7750|Huge 2 BR Upper E...|  17985|            Sing|          Manhattan|       East Harlem|Entire home/apt|              0.0|       null|             249|190.0|           7.0|40.79685|-73.94872|                           2.0| 5.247024072160486|1.3731660529907315|                 10.0|                        0.0|              0.0|   (220,[10],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(232,[0,2,3,4,5,1...|\n",
            "+----+--------------------+-------+----------------+-------------------+------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EquP39l-pNCk"
      },
      "source": [
        "## Train / test Split\n",
        "## Split randon with a seed so you can reproduce the same train /test data as needed\n",
        "seed = 51\n",
        "(testDF, trainDF) = airDF.randomSplit((0.20, 0.80), seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BTXgoRS2WF3",
        "outputId": "2276eaf8-cbbc-4c76-dc6d-24e916704a53"
      },
      "source": [
        "testDF.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9610"
            ]
          },
          "metadata": {},
          "execution_count": 510
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDmfB5V92hom",
        "outputId": "9c22d984-b185-4bac-b493-b0d131e01ede"
      },
      "source": [
        "trainDF.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39277"
            ]
          },
          "metadata": {},
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLeToALu9P8D"
      },
      "source": [
        "## Training\n",
        "## NOTE : A pipeline can have many pipelines.\n",
        "## Here we will now add a Linear Regression Estimator in the pipeline and create a new pipeline which includes our featurization pipeline\n",
        "## Let;s use Price column as the label column and see teh metrics\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "lr = LinearRegression(labelCol=\"price\", featuresCol=\"Model_Features\")\n",
        "air_pipeline_price = Pipeline(stages=[features_pipe, lr])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziZ-1a1_AvAD"
      },
      "source": [
        "## Lets fit on training Data\n",
        "air_lr_model_price = air_pipeline_price.fit(trainDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqbBEkb3Rtd1"
      },
      "source": [
        "lr_price_Summary = air_lr_model_price.stages[-1].summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leFyl2wjR1ib",
        "outputId": "d6f9a06f-10d1-4fd8-e90c-2cb071411be4"
      },
      "source": [
        "lr_price_Summary.r2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11768224332720201"
            ]
          },
          "metadata": {},
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTkrq9YqdwAQ"
      },
      "source": [
        "## Using log price as label\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "lr = LinearRegression(labelCol=\"log_price\", featuresCol=\"Model_Features\",predictionCol=\"predicted_log_price\")\n",
        "air_pipeline_lr = Pipeline(stages=[features_pipe, lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRwxCQ1pd5C3"
      },
      "source": [
        "air_lr_model = air_pipeline_lr.fit(trainDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWRvYNRLd_er"
      },
      "source": [
        "lr_Summary = air_lr_model.stages[-1].summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00QeV0aseGgm",
        "outputId": "0010dec1-6e31-4f79-b1f6-2cb8f8c477ee"
      },
      "source": [
        "## A very better r2 score with log price \n",
        "lr_Summary.r2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5447723505100401"
            ]
          },
          "metadata": {},
          "execution_count": 583
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCYDN6d9KcpN"
      },
      "source": [
        "## GB Tree Model\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "gb=GBTRegressor(labelCol=\"log_price\", featuresCol=\"Model_Features\",predictionCol=\"predicted_log_price\")\n",
        "air_pipeline = Pipeline(stages=[features_pipe, gb])\n",
        "air_gb_model=air_pipeline.fit(trainDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnEYXp2POOr1",
        "outputId": "dc1aae9d-3cd9-4867-f648-b49bd445f796"
      },
      "source": [
        "gb_Summary = air_gb_model.stages[-1]\n",
        "gb_Summary.featureImportances"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(231, {0: 0.0452, 1: 0.0744, 2: 0.1372, 3: 0.0944, 4: 0.0708, 5: 0.0783, 6: 0.0122, 7: 0.0018, 8: 0.0011, 9: 0.0005, 10: 0.0047, 11: 0.0003, 12: 0.0056, 13: 0.001, 14: 0.0004, 15: 0.0053, 16: 0.0005, 17: 0.0003, 19: 0.0047, 21: 0.0015, 22: 0.0017, 25: 0.0044, 26: 0.0015, 28: 0.0007, 31: 0.001, 36: 0.0022, 37: 0.003, 38: 0.001, 39: 0.0028, 40: 0.0033, 41: 0.0019, 44: 0.0005, 45: 0.0014, 47: 0.0003, 49: 0.001, 53: 0.0001, 59: 0.0179, 60: 0.0005, 62: 0.0006, 64: 0.001, 65: 0.0015, 67: 0.0003, 71: 0.001, 79: 0.0018, 80: 0.0008, 81: 0.0005, 84: 0.0036, 87: 0.0007, 89: 0.0008, 105: 0.0005, 106: 0.0024, 120: 0.0009, 131: 0.0017, 134: 0.0005, 140: 0.0003, 144: 0.0017, 155: 0.0085, 181: 0.0002, 194: 0.0039, 206: 0.0022, 225: 0.027, 226: 0.0012, 227: 0.0016, 228: 0.0018, 229: 0.3328, 230: 0.0146})"
            ]
          },
          "metadata": {},
          "execution_count": 553
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UqvTvJtSxGQ"
      },
      "source": [
        "Step 5 - Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCvGRT2ZS3pq",
        "outputId": "a34664c6-352c-41b2-c7fe-64297d4dd042"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator= RegressionEvaluator()\n",
        "print(evaluator.explainParams())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labelCol: label column name. (default: label)\n",
            "metricName: metric name in evaluation - one of:\n",
            "                       rmse - root mean squared error (default)\n",
            "                       mse - mean squared error\n",
            "                       r2 - r^2 metric\n",
            "                       mae - mean absolute error\n",
            "                       var - explained variance. (default: rmse)\n",
            "predictionCol: prediction column name. (default: prediction)\n",
            "throughOrigin: whether the regression is through the origin. (default: False)\n",
            "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOYPHLUcTBxq",
        "outputId": "a455aae9-45da-452d-e029-d27e9fdee2f5"
      },
      "source": [
        "evaluator.setLabelCol(\"log_price\")\n",
        "evaluator.setPredictionCol(\"predicted_log_price\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegressionEvaluator_656ac2e6b64c"
            ]
          },
          "metadata": {},
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBYljlidTfjK",
        "outputId": "921d22f9-9cfb-4718-953b-669a52be8a88"
      },
      "source": [
        "evaluator.evaluate(air_lr_model.transform(testDF))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4687019953405141"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHQ6swQNTobj",
        "outputId": "f8e00226-c2a7-46b8-d3d1-d69a551e7415"
      },
      "source": [
        "##Slightly Better performance with GBT\n",
        "evaluator.evaluate(air_gb_model.transform(testDF))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4493783420789403"
            ]
          },
          "metadata": {},
          "execution_count": 542
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8ZOBHYmMnh"
      },
      "source": [
        "Step 6 -  Model persistence and Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XojfLpFT1Cq"
      },
      "source": [
        "predctionsDF=air_gb_model.transform(testDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzCHhgIOma6F",
        "outputId": "24fd13ce-e9bf-4cf0-8eeb-e1599f1fe8ae"
      },
      "source": [
        "predctionsDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "|   id|                name|host_id|      host_name|neighbourhood_group|       neighbourhood|      room_type|number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|         log_price| reviews_per_month|neighbourhood_indexed|neighbourhood_group_indexed|room_type_indexed|oneHot_neighborhood|oneHOt_neighbourhood_group|oneHot_room_type|      Model_Features|predicted_log_price|\n",
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "| 2539|Clean & quiet apt...|   2787|           John|           Brooklyn|          Kensington|   Private room|              9.0| 2018-10-19|             365|149.0|           1.0|40.64749|-73.97237|                           6.0| 5.003946305945459|              0.21|                 51.0|                        1.0|              1.0|   (219,[51],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.453871058998908|\n",
            "| 5441|Central Manhattan...|   7989|           Kate|          Manhattan|      Hell's Kitchen|   Private room|            188.0| 2019-06-23|              39| 85.0|           2.0|40.76076|-73.98867|                           1.0| 4.442651256490317|               1.5|                  5.0|                        0.0|              1.0|    (219,[5],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.685882886210409|\n",
            "| 5803|Lovely Room 1, Ga...|   9744|         Laurie|           Brooklyn|         South Slope|   Private room|            167.0| 2019-06-24|             314| 89.0|           4.0|40.66829|-73.98779|                           3.0|  4.48863636973214|              1.34|                 38.0|                        1.0|              1.0|   (219,[38],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.342148975328131|\n",
            "| 6848|Only 2 stops to M...|  15991|  Allen & Irina|           Brooklyn|        Williamsburg|Entire home/apt|            148.0| 2019-06-29|              46|140.0|           2.0|40.70837|-73.95352|                           1.0| 4.941642422609304|               1.2|                  0.0|                        1.0|              0.0|    (219,[0],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  5.053841925261502|\n",
            "| 7750|Huge 2 BR Upper E...|  17985|           Sing|          Manhattan|         East Harlem|Entire home/apt|              0.0|       null|             249|190.0|           7.0|40.79685|-73.94872|                           2.0| 5.247024072160486|1.3731660529907315|                 11.0|                        0.0|              0.0|   (219,[11],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,2,3,4,5,1...| 5.3277356184469165|\n",
            "| 8490|MAISON DES SIRENE...|  25183|       Nathalie|           Brooklyn|  Bedford-Stuyvesant|Entire home/apt|             88.0| 2019-06-19|             233|120.0|           2.0|40.68371|-73.94028|                           2.0| 4.787491742782046|              0.73|                  1.0|                        1.0|              0.0|    (219,[1],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.901283765048974|\n",
            "| 9518|SPACIOUS, LOVELY ...|  31374|           Shon|          Manhattan|              Inwood|   Private room|            108.0| 2019-06-15|             311| 44.0|           3.0|40.86482|-73.92106|                           3.0| 3.784189633918261|              1.11|                 40.0|                        0.0|              1.0|   (219,[40],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.221504049431709|\n",
            "| 9668|front room/double...|  32294|Ssameer Or Trip|          Manhattan|              Harlem|   Private room|            242.0| 2019-06-01|             355| 50.0|           3.0|40.82245|-73.95104|                           3.0| 3.912023005428146|              2.04|                  2.0|                        0.0|              1.0|    (219,[2],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.329799768514066|\n",
            "|10962|Lovely room 2 & g...|   9744|         Laurie|           Brooklyn|         South Slope|   Private room|            168.0| 2019-06-21|             340| 89.0|           4.0|40.66869| -73.9878|                           3.0|  4.48863636973214|              1.41|                 38.0|                        1.0|              1.0|   (219,[38],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.342148975328131|\n",
            "|12303|1bdr w private ba...|  47618|        Yolande|           Brooklyn|         Fort Greene|   Private room|             25.0| 2018-09-30|             311|120.0|           7.0|40.69673|-73.97584|                           1.0| 4.787491742782046|              0.23|                 24.0|                        1.0|              1.0|   (219,[24],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.252567245011791|\n",
            "|12627|Entire apartment ...|  49670|           Rana|           Brooklyn|Prospect-Lefferts...|Entire home/apt|             11.0| 2019-06-05|              95|150.0|          29.0|40.65944|-73.96238|                           1.0|5.0106352940962555|              0.49|                 21.0|                        1.0|              0.0|   (219,[21],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.633736124956066|\n",
            "|12940|Charming Brownsto...|  50148|       Adreinne|           Brooklyn|  Bedford-Stuyvesant|Entire home/apt|             61.0| 2019-05-25|             265|110.0|           7.0|40.68111|-73.95591|                           1.0| 4.700480365792417|              0.52|                  1.0|                        1.0|              0.0|    (219,[1],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.918609739687604|\n",
            "|14322|Beautiful Apartme...|  56284|      Francesca|          Manhattan|            Kips Bay|Entire home/apt|             19.0| 2019-03-25|             257|200.0|           7.0|40.73961|-73.98074|                           1.0| 5.298317366548036|              0.22|                 25.0|                        0.0|              0.0|   (219,[25],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  5.487160748499214|\n",
            "|15338|Room in Greenpoin...|  32169|         Andrea|           Brooklyn|          Greenpoint|   Private room|            138.0| 2019-06-04|             320| 49.0|           4.0|40.72401|-73.93788|                           3.0|3.8918202981106265|              1.19|                 12.0|                        1.0|              1.0|   (219,[12],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.146794838926817|\n",
            "|15385|Very, very cozy p...|  60252|       Cristina|           Brooklyn|        Williamsburg|   Private room|             42.0| 2019-06-30|             263| 80.0|           2.0|40.71185|-73.96204|                           1.0| 4.382026634673881|              0.38|                  0.0|                        1.0|              1.0|    (219,[0],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...| 4.4284128195701955|\n",
            "|15711|2 bedroom - Upper...|  61491|              D|          Manhattan|     Upper East Side|Entire home/apt|             66.0| 2019-03-30|             231|250.0|           2.0|40.77065|-73.95269|                           2.0| 5.521460917862246|              0.57|                  7.0|                        0.0|              0.0|    (219,[7],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...| 5.2674255272200705|\n",
            "|16338|Double Room w Pri...|  63613|       Patricia|           Brooklyn|        Clinton Hill|   Private room|             27.0| 2017-09-30|             292| 55.0|           7.0|   40.69|-73.96788|                           2.0| 4.007333185232471|              0.23|                 19.0|                        1.0|              1.0|   (219,[19],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.242551450513386|\n",
            "|16580|Sunny, Modern roo...|  64442|           Reka|          Manhattan|        East Village|   Private room|            338.0| 2019-07-01|              72| 80.0|           1.0|40.72649|-73.97904|                           2.0| 4.382026634673881|              4.72|                  6.0|                        0.0|              1.0|    (219,[6],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.589792628453856|\n",
            "|18198|Little King of Qu...|  70091|         Justin|             Queens|            Woodside|   Private room|             25.0| 2019-05-31|             324| 70.0|          30.0|40.75038|-73.90334|                           1.0| 4.248495242049359|              0.22|                 44.0|                        2.0|              1.0|   (219,[44],[1.0])|             (4,[2],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...| 3.6773966908016975|\n",
            "|19159|Spacious luminous...|  73051|        Sybilla|          Manhattan|              Harlem|Entire home/apt|             54.0| 2019-03-23|             209|110.0|          31.0|40.82915|-73.95136|                           1.0| 4.700480365792417|              0.49|                  2.0|                        0.0|              0.0|    (219,[2],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.983335170068298|\n",
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln7xQV0dmeDC"
      },
      "source": [
        "## Saving the model for  inference later\n",
        "air_gb_model.save(\"/content/models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fiIawB7o9Ur",
        "outputId": "81a4b2e7-b757-4e83-bd15-3355288bee73"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AB_NYC_2019.csv  models       spark-3.1.2-bin-hadoop2.7\n",
            "listings.csv\t sample_data  spark-3.1.2-bin-hadoop2.7.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7dZCDSbpkch",
        "outputId": "74964b19-9127-4a63-a7f6-2bcaa4f59419"
      },
      "source": [
        "!ls models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata  stages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgYvwvf9p0NM",
        "outputId": "10003c1f-0e77-45de-e60a-c6577e8ef9cc"
      },
      "source": [
        "!ls models/stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_PipelineModel_f4ed09c47006  1_GBTRegressor_cf21c5dc6a2c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7iNWcSbp5Po"
      },
      "source": [
        "## Loading the model back from storage\n",
        "from pyspark.ml.pipeline import PipelineModel\n",
        "loaded_gb_model = PipelineModel.load(\"/content/models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cGdf_yIr6ZH"
      },
      "source": [
        "predctionsDF=loaded_gb_model.transform(testDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUl7QyENt4K-",
        "outputId": "d485cd69-94a7-4f83-e66e-696de9128e52"
      },
      "source": [
        "predctionsDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "|   id|                name|host_id|      host_name|neighbourhood_group|       neighbourhood|      room_type|number_of_reviews|last_review|availability_365|price|minimum_nights|latitude|longitude|calculated_host_listings_count|         log_price| reviews_per_month|neighbourhood_indexed|neighbourhood_group_indexed|room_type_indexed|oneHot_neighborhood|oneHOt_neighbourhood_group|oneHot_room_type|      Model_Features|predicted_log_price|\n",
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "| 2539|Clean & quiet apt...|   2787|           John|           Brooklyn|          Kensington|   Private room|              9.0| 2018-10-19|             365|149.0|           1.0|40.64749|-73.97237|                           6.0| 5.003946305945459|              0.21|                 51.0|                        1.0|              1.0|   (219,[51],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.453871058998908|\n",
            "| 5441|Central Manhattan...|   7989|           Kate|          Manhattan|      Hell's Kitchen|   Private room|            188.0| 2019-06-23|              39| 85.0|           2.0|40.76076|-73.98867|                           1.0| 4.442651256490317|               1.5|                  5.0|                        0.0|              1.0|    (219,[5],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.685882886210409|\n",
            "| 5803|Lovely Room 1, Ga...|   9744|         Laurie|           Brooklyn|         South Slope|   Private room|            167.0| 2019-06-24|             314| 89.0|           4.0|40.66829|-73.98779|                           3.0|  4.48863636973214|              1.34|                 38.0|                        1.0|              1.0|   (219,[38],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.342148975328131|\n",
            "| 6848|Only 2 stops to M...|  15991|  Allen & Irina|           Brooklyn|        Williamsburg|Entire home/apt|            148.0| 2019-06-29|              46|140.0|           2.0|40.70837|-73.95352|                           1.0| 4.941642422609304|               1.2|                  0.0|                        1.0|              0.0|    (219,[0],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  5.053841925261502|\n",
            "| 7750|Huge 2 BR Upper E...|  17985|           Sing|          Manhattan|         East Harlem|Entire home/apt|              0.0|       null|             249|190.0|           7.0|40.79685|-73.94872|                           2.0| 5.247024072160486|1.3731660529907315|                 11.0|                        0.0|              0.0|   (219,[11],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,2,3,4,5,1...| 5.3277356184469165|\n",
            "| 8490|MAISON DES SIRENE...|  25183|       Nathalie|           Brooklyn|  Bedford-Stuyvesant|Entire home/apt|             88.0| 2019-06-19|             233|120.0|           2.0|40.68371|-73.94028|                           2.0| 4.787491742782046|              0.73|                  1.0|                        1.0|              0.0|    (219,[1],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.901283765048974|\n",
            "| 9518|SPACIOUS, LOVELY ...|  31374|           Shon|          Manhattan|              Inwood|   Private room|            108.0| 2019-06-15|             311| 44.0|           3.0|40.86482|-73.92106|                           3.0| 3.784189633918261|              1.11|                 40.0|                        0.0|              1.0|   (219,[40],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.221504049431709|\n",
            "| 9668|front room/double...|  32294|Ssameer Or Trip|          Manhattan|              Harlem|   Private room|            242.0| 2019-06-01|             355| 50.0|           3.0|40.82245|-73.95104|                           3.0| 3.912023005428146|              2.04|                  2.0|                        0.0|              1.0|    (219,[2],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.329799768514066|\n",
            "|10962|Lovely room 2 & g...|   9744|         Laurie|           Brooklyn|         South Slope|   Private room|            168.0| 2019-06-21|             340| 89.0|           4.0|40.66869| -73.9878|                           3.0|  4.48863636973214|              1.41|                 38.0|                        1.0|              1.0|   (219,[38],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.342148975328131|\n",
            "|12303|1bdr w private ba...|  47618|        Yolande|           Brooklyn|         Fort Greene|   Private room|             25.0| 2018-09-30|             311|120.0|           7.0|40.69673|-73.97584|                           1.0| 4.787491742782046|              0.23|                 24.0|                        1.0|              1.0|   (219,[24],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.252567245011791|\n",
            "|12627|Entire apartment ...|  49670|           Rana|           Brooklyn|Prospect-Lefferts...|Entire home/apt|             11.0| 2019-06-05|              95|150.0|          29.0|40.65944|-73.96238|                           1.0|5.0106352940962555|              0.49|                 21.0|                        1.0|              0.0|   (219,[21],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.633736124956066|\n",
            "|12940|Charming Brownsto...|  50148|       Adreinne|           Brooklyn|  Bedford-Stuyvesant|Entire home/apt|             61.0| 2019-05-25|             265|110.0|           7.0|40.68111|-73.95591|                           1.0| 4.700480365792417|              0.52|                  1.0|                        1.0|              0.0|    (219,[1],[1.0])|             (4,[1],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.918609739687604|\n",
            "|14322|Beautiful Apartme...|  56284|      Francesca|          Manhattan|            Kips Bay|Entire home/apt|             19.0| 2019-03-25|             257|200.0|           7.0|40.73961|-73.98074|                           1.0| 5.298317366548036|              0.22|                 25.0|                        0.0|              0.0|   (219,[25],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  5.487160748499214|\n",
            "|15338|Room in Greenpoin...|  32169|         Andrea|           Brooklyn|          Greenpoint|   Private room|            138.0| 2019-06-04|             320| 49.0|           4.0|40.72401|-73.93788|                           3.0|3.8918202981106265|              1.19|                 12.0|                        1.0|              1.0|   (219,[12],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.146794838926817|\n",
            "|15385|Very, very cozy p...|  60252|       Cristina|           Brooklyn|        Williamsburg|   Private room|             42.0| 2019-06-30|             263| 80.0|           2.0|40.71185|-73.96204|                           1.0| 4.382026634673881|              0.38|                  0.0|                        1.0|              1.0|    (219,[0],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...| 4.4284128195701955|\n",
            "|15711|2 bedroom - Upper...|  61491|              D|          Manhattan|     Upper East Side|Entire home/apt|             66.0| 2019-03-30|             231|250.0|           2.0|40.77065|-73.95269|                           2.0| 5.521460917862246|              0.57|                  7.0|                        0.0|              0.0|    (219,[7],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...| 5.2674255272200705|\n",
            "|16338|Double Room w Pri...|  63613|       Patricia|           Brooklyn|        Clinton Hill|   Private room|             27.0| 2017-09-30|             292| 55.0|           7.0|   40.69|-73.96788|                           2.0| 4.007333185232471|              0.23|                 19.0|                        1.0|              1.0|   (219,[19],[1.0])|             (4,[1],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.242551450513386|\n",
            "|16580|Sunny, Modern roo...|  64442|           Reka|          Manhattan|        East Village|   Private room|            338.0| 2019-07-01|              72| 80.0|           1.0|40.72649|-73.97904|                           2.0| 4.382026634673881|              4.72|                  6.0|                        0.0|              1.0|    (219,[6],[1.0])|             (4,[0],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...|  4.589792628453856|\n",
            "|18198|Little King of Qu...|  70091|         Justin|             Queens|            Woodside|   Private room|             25.0| 2019-05-31|             324| 70.0|          30.0|40.75038|-73.90334|                           1.0| 4.248495242049359|              0.22|                 44.0|                        2.0|              1.0|   (219,[44],[1.0])|             (4,[2],[1.0])|   (2,[1],[1.0])|(231,[0,1,2,3,4,5...| 3.6773966908016975|\n",
            "|19159|Spacious luminous...|  73051|        Sybilla|          Manhattan|              Harlem|Entire home/apt|             54.0| 2019-03-23|             209|110.0|          31.0|40.82915|-73.95136|                           1.0| 4.700480365792417|              0.49|                  2.0|                        0.0|              0.0|    (219,[2],[1.0])|             (4,[0],[1.0])|   (2,[0],[1.0])|(231,[0,1,2,3,4,5...|  4.983335170068298|\n",
            "+-----+--------------------+-------+---------------+-------------------+--------------------+---------------+-----------------+-----------+----------------+-----+--------------+--------+---------+------------------------------+------------------+------------------+---------------------+---------------------------+-----------------+-------------------+--------------------------+----------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29VhnL9EuQKH"
      },
      "source": [
        "Hyperparameter/ Model Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Qh0EM6u3-e"
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "paramGrid = (ParamGridBuilder()\n",
        "  .addGrid(lr.elasticNetParam, [0., 1.])\n",
        "  .addGrid(lr.maxIter, [1, 10, 100])\n",
        "  .addGrid(lr.fitIntercept, [True, False])\n",
        "  .build()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDFNcaQlv6DV"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(\n",
        "  estimator = air_pipeline_lr,         \n",
        "  estimatorParamMaps = paramGrid,   \n",
        "  evaluator=evaluator,             \n",
        "  numFolds = 3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyZLhWrTwWgF"
      },
      "source": [
        "cvModel_lr = cv.fit(trainDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbkCrbm6wZ3d",
        "outputId": "70dad33f-6f7c-4537-c425-39f0d80db9d1"
      },
      "source": [
        "evaluator.evaluate(cvModel_lr.transform(testDF))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4687019953405141"
            ]
          },
          "metadata": {},
          "execution_count": 588
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMfp9ZPbxCBl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}